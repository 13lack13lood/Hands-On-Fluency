# Hands-on Fluency

A full-stack sign language learning platform built during the NewHacks hackathon. It teaches and quizes the user on sign language content using the webcam with OpenCV and MediaPipe. A CNN (Convolutional Neural Network) was designed using TensorFlow for hand guesture recognition, resulting in a 61% accuracy across 30 distinct classes. A Flask backend was developed to seamlessly integrate the React frontend with the SQLite database for user authentication and the hand guesture recognitional model.

[Link to Backend](https://github.com/13lack13lood/Hands-On-Fluency-backend/)

## Technologies Used
- React
- Tailwind
- Flask
- SQLite
- TensorFlow
- OpenCV
- MediaPipe

## Current Features
- User login/authentication
- User account creation and can select their current sign language ability
- Flash cards to learn sign language
- Quizzes through webcam and detects if the user perform the correct given sign
  - If the user performed the wrong sign, it will say what the user performed and ask to try again

https://github.com/13lack13lood/Hands-On-Fluency/assets/44007891/1ffd5256-5db5-414f-9e61-f40012a92c2c



